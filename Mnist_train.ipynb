{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85c858c8",
   "metadata": {},
   "source": [
    "## 深度學習系列| 解讀LeNet及PyTorch實現\n",
    "###  from [CSDN](https://blog.csdn.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b1e9e97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeModel(\n",
      "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(20, 40, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (FC1): Linear(in_features=640, out_features=64, bias=True)\n",
      "  (Classifier): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class LeModel(nn.Module):\n",
    "    def __init__(self, num_class=10):\n",
    "        super(LeModel, self).__init__()\n",
    "        # CONV2d(in_ch, out_ch, k_size)\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5)   # 1x28x28 -> 20x24x24\n",
    "        self.pool1 = nn.MaxPool2d(2)    # 20x24x24 -> 20x12x12\n",
    "        self.conv2 = nn.Conv2d(20, 40, 5)    # 20x12x12 -> 40x8x8\n",
    "        self.pool2 = nn.MaxPool2d(2)    # 16x8x8 -> 40x4x4\n",
    "        #self.conv3 = nn.Conv2d(20, 120, 4)  # LeNet的input是32x32，MNIST为28x28，对此修改卷积核尺寸为4x4\n",
    "        self.FC1 = nn.Linear(640*1*1, 64)\n",
    "        self.Classifier = nn.Linear(64, num_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        #x = torch.tanh(self.conv3(x))\n",
    "        x = x.view(-1, 640*1*1)\n",
    "        x = self.FC1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.Classifier(x)\n",
    "        return x\n",
    "\n",
    "model = LeModel(num_class=10)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7d61af34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchsummary\n",
    "\n",
    "# torchsummary.summary(model, input_size = (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f8f311ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is cuda\n",
      "3750\n",
      "625\n",
      "epoch: 1 | step:   500 | train_loss: 2.12691 |\n",
      "epoch: 1 | step:  1000 | train_loss: 1.04497 |\n",
      "epoch: 1 | step:  1500 | train_loss: 0.45314 |\n",
      "epoch: 1 | step:  2000 | train_loss: 0.34180 |\n",
      "epoch: 1 | step:  2500 | train_loss: 0.29405 |\n",
      "epoch: 1 | step:  3000 | train_loss: 0.25984 |\n",
      "epoch: 1 | step:  3500 | train_loss: 0.23797 |\n",
      "epoch: 2 | step:   500 | train_loss: 0.19776 |\n",
      "epoch: 2 | step:  1000 | train_loss: 0.19280 |\n",
      "epoch: 2 | step:  1500 | train_loss: 0.16871 |\n",
      "epoch: 2 | step:  2000 | train_loss: 0.16147 |\n",
      "epoch: 2 | step:  2500 | train_loss: 0.15796 |\n",
      "epoch: 2 | step:  3000 | train_loss: 0.14186 |\n",
      "epoch: 2 | step:  3500 | train_loss: 0.14704 |\n",
      "epoch: 3 | step:   500 | train_loss: 0.11557 |\n",
      "epoch: 3 | step:  1000 | train_loss: 0.12571 |\n",
      "epoch: 3 | step:  1500 | train_loss: 0.12755 |\n",
      "epoch: 3 | step:  2000 | train_loss: 0.11465 |\n",
      "epoch: 3 | step:  2500 | train_loss: 0.10722 |\n",
      "epoch: 3 | step:  3000 | train_loss: 0.11424 |\n",
      "epoch: 3 | step:  3500 | train_loss: 0.09784 |\n",
      "epoch: 4 | step:   500 | train_loss: 0.09492 |\n",
      "epoch: 4 | step:  1000 | train_loss: 0.09513 |\n",
      "epoch: 4 | step:  1500 | train_loss: 0.08908 |\n",
      "epoch: 4 | step:  2000 | train_loss: 0.08456 |\n",
      "epoch: 4 | step:  2500 | train_loss: 0.09533 |\n",
      "epoch: 4 | step:  3000 | train_loss: 0.08045 |\n",
      "epoch: 4 | step:  3500 | train_loss: 0.08821 |\n",
      "epoch: 5 | step:   500 | train_loss: 0.07415 |\n",
      "epoch: 5 | step:  1000 | train_loss: 0.08149 |\n",
      "epoch: 5 | step:  1500 | train_loss: 0.07896 |\n",
      "epoch: 5 | step:  2000 | train_loss: 0.07719 |\n",
      "epoch: 5 | step:  2500 | train_loss: 0.07513 |\n",
      "epoch: 5 | step:  3000 | train_loss: 0.08024 |\n",
      "epoch: 5 | step:  3500 | train_loss: 0.06894 |\n",
      "epoch: 6 | step:   500 | train_loss: 0.07032 |\n",
      "epoch: 6 | step:  1000 | train_loss: 0.06767 |\n",
      "epoch: 6 | step:  1500 | train_loss: 0.06302 |\n",
      "epoch: 6 | step:  2000 | train_loss: 0.06948 |\n",
      "epoch: 6 | step:  2500 | train_loss: 0.07284 |\n",
      "epoch: 6 | step:  3000 | train_loss: 0.06280 |\n",
      "epoch: 6 | step:  3500 | train_loss: 0.06256 |\n",
      "epoch: 7 | step:   500 | train_loss: 0.05717 |\n",
      "epoch: 7 | step:  1000 | train_loss: 0.06076 |\n",
      "epoch: 7 | step:  1500 | train_loss: 0.06483 |\n",
      "epoch: 7 | step:  2000 | train_loss: 0.06435 |\n",
      "epoch: 7 | step:  2500 | train_loss: 0.05836 |\n",
      "epoch: 7 | step:  3000 | train_loss: 0.05421 |\n",
      "epoch: 7 | step:  3500 | train_loss: 0.05672 |\n",
      "epoch: 8 | step:   500 | train_loss: 0.05881 |\n",
      "epoch: 8 | step:  1000 | train_loss: 0.04629 |\n",
      "epoch: 8 | step:  1500 | train_loss: 0.05904 |\n",
      "epoch: 8 | step:  2000 | train_loss: 0.05297 |\n",
      "epoch: 8 | step:  2500 | train_loss: 0.05298 |\n",
      "epoch: 8 | step:  3000 | train_loss: 0.05091 |\n",
      "epoch: 8 | step:  3500 | train_loss: 0.05758 |\n",
      "epoch: 9 | step:   500 | train_loss: 0.05312 |\n",
      "epoch: 9 | step:  1000 | train_loss: 0.04314 |\n",
      "epoch: 9 | step:  1500 | train_loss: 0.05265 |\n",
      "epoch: 9 | step:  2000 | train_loss: 0.04738 |\n",
      "epoch: 9 | step:  2500 | train_loss: 0.04852 |\n",
      "epoch: 9 | step:  3000 | train_loss: 0.04671 |\n",
      "epoch: 9 | step:  3500 | train_loss: 0.05232 |\n",
      "epoch: 10 | step:   500 | train_loss: 0.04273 |\n",
      "epoch: 10 | step:  1000 | train_loss: 0.04540 |\n",
      "epoch: 10 | step:  1500 | train_loss: 0.04892 |\n",
      "epoch: 10 | step:  2000 | train_loss: 0.04066 |\n",
      "epoch: 10 | step:  2500 | train_loss: 0.04716 |\n",
      "epoch: 10 | step:  3000 | train_loss: 0.04377 |\n",
      "epoch: 10 | step:  3500 | train_loss: 0.04794 |\n",
      "Finished Training !\n",
      "Accuracy of the network on the 10000 test images: 98 %\n",
      "correct =  9854\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "#from LeNet import LeModel\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "# MNIST.resources = [\n",
    "#     ('file:///C:/Users/henry_esslab/MNIST/raw/train-images.idx3-ubyte','f68b3c2dcbeaaa9fbdd348bbdeb94873'),\n",
    "#     ('file:///C:/Users/henry_esslab/MNIST/raw/train-labels.idx1-ubyte','d53e105ee54ea40749a09fcbcd1e9432'),\n",
    "#     ('file:///C:/Users/henry_esslab/MNIST/raw/t10k-images.idx3-ubyte','9fb629c4189551a2d022fa330f9573f3'),\n",
    "#     ('file:///C:/Users/henry_esslab/MNIST/raw/t10k-labels.idx1-ubyte','ec29112dd5afa0611ce80d1b7f02629c')\n",
    "   \n",
    "# ]\n",
    "\n",
    "def main():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'device is {device}')\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                   transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "    train_data = MNIST(root='./torch_v2', train=True,\n",
    "                       transform=transform, download=True)\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "\n",
    "    test_data = MNIST(root='./torch_v2', train=False,\n",
    "                      transform=transform, download=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=16, shuffle=True)\n",
    "    #------------------\n",
    "    \n",
    "    i = 0\n",
    "    for images, labels in train_loader:\n",
    "        i = i + 1\n",
    "    print(i)\n",
    "    i = 0\n",
    "    for images, labels in test_loader:\n",
    "        i = i + 1\n",
    "    print(i)\n",
    "\n",
    "    net = LeModel()\n",
    "    net.to(device)\n",
    "\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.5)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "    net.train()\n",
    "    # .train 是用來啟動 batch norm & drop out\n",
    "    for epoch in range(10):\n",
    "        running_loss = 0.0\n",
    "        for step, (images, labels) in enumerate(train_loader, start=0):\n",
    "            optimizer.zero_grad()\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            output = net(images)\n",
    "            loss = loss_function(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if step % 500 == 499:\n",
    "                print('epoch: %d | step: %5d | train_loss: %.5f |' % (epoch+1, step+1, running_loss/500))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training !')\n",
    "\n",
    "    net.eval()\n",
    "    # .eval 是用來關閉 batch norm & drop out\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            output = net(images)\n",
    "            _, predict = torch.max(output.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predict == labels).sum().item()\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "            100 * correct / total))\n",
    "    print(\"correct = \", correct)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7e132a46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('conv1.weight', tensor([[[[ 1.6563e-01,  6.3334e-02, -4.7992e-02, -2.2683e-02, -6.0129e-02],\n",
      "          [-4.1120e-02, -9.0243e-02,  8.2592e-02, -1.0827e-01, -1.5185e-01],\n",
      "          [ 8.5585e-02,  1.7002e-01,  1.5753e-01,  8.5149e-02,  1.9356e-01],\n",
      "          [-1.3267e-01, -1.0448e-01,  2.8872e-02, -6.4907e-02, -8.6202e-02],\n",
      "          [ 1.3070e-01,  1.4237e-02,  1.8222e-01, -1.3658e-02, -3.7670e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.9609e-03,  9.4502e-02, -6.2343e-02, -3.7039e-02,  2.9607e-02],\n",
      "          [ 9.3575e-02, -4.4024e-02,  1.8271e-01, -1.4949e-01, -1.0058e-01],\n",
      "          [ 1.2397e-01, -4.4526e-02, -3.6121e-02,  3.0935e-02,  1.6570e-01],\n",
      "          [-1.5374e-01, -1.5736e-01, -5.0952e-02,  6.0303e-02, -6.4847e-02],\n",
      "          [-1.9371e-01,  1.4333e-02,  6.7919e-02, -1.7876e-01,  1.1651e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.6043e-01,  8.2260e-02, -1.7355e-01,  3.2294e-02, -1.7909e-01],\n",
      "          [-1.7120e-01,  3.7142e-02,  2.2420e-02, -1.9025e-01,  1.3233e-01],\n",
      "          [ 1.0714e-01, -2.8777e-03,  1.7106e-01, -9.2693e-02,  1.5398e-01],\n",
      "          [ 8.7796e-02,  2.1993e-02, -6.1048e-02,  1.8277e-01, -1.7274e-01],\n",
      "          [-5.6526e-02, -6.9240e-02,  4.1311e-03, -1.2212e-01, -1.7487e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7160e-01, -8.3228e-02,  1.5337e-01, -1.7204e-01,  1.6601e-01],\n",
      "          [ 1.0572e-01,  1.3220e-02, -7.9949e-02,  1.7691e-01,  6.1466e-02],\n",
      "          [ 2.5813e-02,  1.7539e-01,  1.5656e-01,  1.7677e-01, -1.7870e-01],\n",
      "          [-3.2090e-02,  1.7194e-01, -1.1583e-01,  3.3706e-02, -1.8048e-02],\n",
      "          [-1.0996e-01, -2.5959e-02, -7.3331e-02,  1.8782e-01,  1.7113e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7805e-01,  8.8047e-02, -1.9785e-01,  1.7698e-01,  1.8810e-01],\n",
      "          [-1.3766e-01, -1.0552e-01,  2.3713e-02,  3.0835e-02, -1.6458e-02],\n",
      "          [ 1.5825e-01, -1.8984e-01,  6.4551e-02, -1.5134e-01, -1.2235e-01],\n",
      "          [-1.2677e-01, -1.6171e-01, -1.3739e-01, -5.1657e-02, -1.7268e-01],\n",
      "          [ 1.2692e-01,  1.7858e-01, -7.9656e-02, -6.1569e-02,  6.0551e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7409e-02,  7.0199e-02, -3.6913e-02,  1.6004e-01, -4.8501e-02],\n",
      "          [-1.5999e-01, -1.7901e-02,  1.0193e-01, -1.5358e-01, -5.8525e-02],\n",
      "          [ 1.7113e-02, -1.5569e-01,  1.1014e-01,  7.3519e-02,  1.7297e-01],\n",
      "          [-1.3912e-01, -1.9970e-01,  5.5870e-02, -1.8659e-01,  1.6246e-01],\n",
      "          [ 6.6238e-02, -1.0474e-01,  1.2521e-01,  1.6116e-01, -1.4940e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.9144e-01, -1.6947e-01,  1.8996e-01,  1.2203e-01, -1.3481e-01],\n",
      "          [-6.4939e-02, -1.8901e-01,  1.8739e-01,  1.9346e-02, -6.6534e-02],\n",
      "          [-2.7736e-02, -1.9674e-01,  7.4542e-02, -1.3955e-01,  1.6933e-01],\n",
      "          [ 1.0497e-01,  7.9476e-02,  1.4711e-01,  1.0149e-01,  1.6481e-01],\n",
      "          [ 7.4986e-02,  6.7743e-02,  9.2420e-02,  1.1441e-01, -1.5738e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2724e-01,  1.6435e-01, -1.5086e-01, -4.1462e-02,  1.5528e-01],\n",
      "          [ 1.5753e-02, -1.3908e-01, -1.7227e-01, -8.6133e-02,  2.9797e-02],\n",
      "          [-3.1097e-02,  1.1284e-01,  2.5346e-02,  1.0210e-01,  9.4056e-02],\n",
      "          [-1.5624e-01,  1.1844e-01,  1.9672e-01,  1.1269e-01, -9.7171e-02],\n",
      "          [-7.2482e-02, -4.6179e-05, -7.2615e-02, -8.4320e-03,  4.1467e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1963e-01, -1.6694e-01,  3.6834e-02,  1.8337e-01, -1.7404e-02],\n",
      "          [-4.7770e-02,  4.8988e-02,  1.7889e-01,  1.7575e-01, -9.5760e-02],\n",
      "          [ 1.2434e-01, -1.8601e-01, -1.0679e-01, -1.1097e-01,  1.5554e-01],\n",
      "          [ 1.3026e-01,  4.5082e-02,  1.2949e-01, -5.0322e-02, -1.5823e-01],\n",
      "          [-2.9758e-02,  1.2245e-01,  1.3083e-01, -2.1815e-02,  1.4914e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.9484e-02,  3.3038e-02, -1.5985e-02, -1.1788e-02,  1.9504e-01],\n",
      "          [ 8.3117e-02,  1.5917e-01,  1.8678e-01, -1.1441e-01, -1.4956e-01],\n",
      "          [-1.2164e-01, -1.6968e-02,  4.5769e-02, -1.2881e-01,  1.0446e-01],\n",
      "          [ 1.1912e-01,  1.5033e-01,  1.6547e-01, -1.3475e-01,  8.4438e-02],\n",
      "          [ 8.6239e-02,  1.5395e-01, -1.9314e-01, -1.1451e-02, -1.1715e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.8267e-01, -1.8930e-01, -1.2924e-01, -7.8227e-02,  9.4018e-02],\n",
      "          [ 1.2933e-01, -1.1358e-01, -3.0836e-02,  8.1907e-02, -1.8647e-01],\n",
      "          [-2.7333e-02,  1.6469e-01, -1.1059e-01,  1.8155e-01,  7.3056e-02],\n",
      "          [-7.5925e-02,  1.3548e-01,  1.8353e-01,  4.8897e-02, -9.0588e-03],\n",
      "          [ 3.0225e-02, -1.6253e-01,  1.1011e-01, -1.0829e-01, -8.7210e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8567e-01,  1.6863e-01,  1.2516e-01,  1.0862e-01,  1.4929e-01],\n",
      "          [ 1.8062e-01, -6.8209e-02,  6.1978e-02,  1.0645e-01, -1.5948e-02],\n",
      "          [-1.1511e-01, -1.6860e-01, -1.2501e-01,  8.0815e-02,  9.3837e-02],\n",
      "          [-1.6516e-01, -6.4229e-02, -1.3277e-01,  3.5720e-02,  1.3055e-01],\n",
      "          [ 1.5582e-01,  7.7678e-02,  1.5694e-01, -7.4648e-02, -1.4467e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6549e-02,  8.8030e-02, -5.5981e-02, -7.3501e-02, -1.0275e-02],\n",
      "          [ 4.0380e-03,  2.0508e-02, -7.4603e-02,  8.1808e-03,  1.2626e-01],\n",
      "          [-1.3203e-01, -1.7532e-01,  1.3658e-01,  1.0315e-01,  1.9714e-01],\n",
      "          [ 1.4658e-01,  6.9306e-02, -1.9551e-01, -5.2993e-02,  8.4335e-02],\n",
      "          [ 1.7588e-01,  1.2944e-01,  1.8792e-01, -1.6513e-01,  1.1332e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7336e-01,  6.7714e-02, -4.3443e-02, -8.9800e-02,  9.4770e-02],\n",
      "          [-1.6428e-01, -1.7490e-01, -5.8289e-02, -1.5640e-01,  9.7024e-02],\n",
      "          [ 4.6316e-02, -1.8177e-01,  3.9909e-02,  3.3699e-02,  5.4655e-02],\n",
      "          [ 8.3671e-02,  4.8160e-02,  1.7253e-01, -5.2131e-02, -9.8421e-02],\n",
      "          [ 1.8959e-01, -1.9676e-01, -6.6172e-02, -1.2448e-01,  4.6988e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.4132e-02,  2.7589e-02,  2.1796e-02,  1.0278e-01, -1.2721e-01],\n",
      "          [ 1.6963e-01, -9.1217e-02, -1.0654e-01, -7.2684e-02,  1.2983e-01],\n",
      "          [ 2.0365e-02, -1.2935e-01,  1.2054e-01,  1.6690e-01, -3.0022e-02],\n",
      "          [ 2.7942e-02,  1.6039e-01, -5.2421e-02, -2.9222e-02, -7.3076e-02],\n",
      "          [-8.9271e-02, -1.9969e-01,  1.9597e-01, -1.9290e-01, -1.4711e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.5074e-02,  1.3076e-02, -3.4729e-02, -1.0202e-01,  1.3539e-01],\n",
      "          [-1.2807e-01, -2.4478e-02,  8.5720e-02, -6.3456e-02, -5.5772e-02],\n",
      "          [ 2.8894e-02,  1.5867e-01,  1.7672e-01,  7.7499e-02,  1.7964e-01],\n",
      "          [ 4.8927e-02,  1.4921e-01, -9.3320e-02, -1.5921e-01, -1.5988e-01],\n",
      "          [-1.3346e-02, -1.5460e-02,  1.9141e-01,  9.0656e-02,  1.5502e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.1845e-02, -1.4786e-01,  5.2650e-02, -3.5913e-02,  5.0000e-02],\n",
      "          [-8.6769e-02,  1.7925e-01,  1.7067e-01, -1.3400e-01,  1.7812e-01],\n",
      "          [ 4.4329e-02,  1.7499e-01,  1.2904e-01,  1.7176e-01, -7.6958e-02],\n",
      "          [-1.6076e-01, -8.3392e-02,  1.5712e-01,  5.9559e-02, -5.4750e-02],\n",
      "          [-1.1554e-01, -1.4584e-01, -1.7348e-01, -3.1078e-02,  6.8488e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2479e-01,  1.8110e-01,  7.9004e-02, -6.6028e-02,  1.6490e-02],\n",
      "          [-2.5312e-02, -2.1235e-02, -1.9303e-01,  6.7667e-02, -5.3691e-02],\n",
      "          [-9.2200e-02, -2.6172e-02, -8.8155e-02, -2.9442e-02, -7.2334e-02],\n",
      "          [-1.6818e-01,  7.9824e-02, -1.8216e-01,  4.9473e-03, -2.2388e-02],\n",
      "          [-9.3441e-03,  4.1457e-02,  1.0542e-01, -5.9367e-03, -2.6313e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8153e-01, -1.9026e-01,  1.2860e-01, -1.6996e-01,  5.0832e-02],\n",
      "          [ 4.2185e-04, -5.5766e-02, -4.4444e-02,  6.4925e-02, -1.1785e-01],\n",
      "          [ 1.4669e-01, -1.4378e-01,  1.7183e-01,  4.8844e-02, -9.7200e-02],\n",
      "          [ 1.3517e-01, -5.2775e-02,  1.3284e-01,  4.0034e-02, -1.3820e-02],\n",
      "          [-1.5661e-01, -1.6867e-01, -1.7656e-01,  1.5875e-01, -9.9216e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2644e-01, -1.5274e-01, -9.8067e-02, -1.3314e-01, -1.1076e-01],\n",
      "          [-1.8724e-01,  1.7607e-01,  1.6936e-01,  1.6453e-01,  6.6447e-02],\n",
      "          [ 1.2815e-01, -8.5985e-02,  8.8394e-02,  1.7182e-02,  1.7216e-01],\n",
      "          [ 4.7713e-02, -2.9198e-02,  2.8084e-02, -5.6425e-02, -1.6244e-01],\n",
      "          [-9.8007e-02, -1.3183e-01, -1.3883e-01, -1.7364e-01, -6.8806e-02]]]])), ('conv1.bias', tensor([ 0.1998,  0.0407, -0.1890, -0.1038,  0.1403,  0.1416, -0.1094, -0.0419,\n",
      "         0.0705,  0.1361,  0.0272, -0.1712, -0.1503,  0.0323,  0.1631, -0.0483,\n",
      "        -0.0955, -0.0366, -0.1327,  0.0177])), ('conv2.weight', tensor([[[[-9.3777e-03, -1.8285e-02,  2.1784e-02, -1.8682e-02,  9.2938e-04],\n",
      "          [-1.5612e-02, -2.7976e-02,  5.9663e-03,  4.3808e-02,  2.3067e-02],\n",
      "          [-2.3377e-04,  4.3988e-02, -7.3369e-03, -1.6052e-02, -1.9999e-02],\n",
      "          [ 2.7488e-03,  5.9923e-03, -1.3929e-02,  3.4207e-02, -3.7883e-02],\n",
      "          [-2.5288e-02, -1.9312e-02, -1.1502e-02, -3.9591e-02,  3.4765e-02]],\n",
      "\n",
      "         [[-1.7754e-02,  2.5282e-02,  1.1804e-02, -7.3891e-03,  3.2559e-02],\n",
      "          [ 3.3361e-02,  1.1500e-04,  3.0261e-02, -6.5041e-03,  2.3264e-02],\n",
      "          [ 2.0150e-02,  1.9458e-02, -4.1256e-02,  1.7677e-02,  2.5902e-02],\n",
      "          [-1.3654e-02, -1.6389e-02,  2.4148e-02,  4.0261e-02, -3.4099e-02],\n",
      "          [ 3.0935e-03, -2.7159e-02,  5.0302e-03, -1.3131e-02, -4.0724e-02]],\n",
      "\n",
      "         [[-2.3754e-02,  2.8751e-02,  3.5281e-02, -1.3835e-02, -3.2441e-02],\n",
      "          [ 3.9410e-02, -3.2895e-02, -2.8771e-02, -1.3797e-02,  2.4170e-02],\n",
      "          [ 4.2888e-02, -9.6678e-04,  1.0840e-02,  4.3766e-02, -3.8849e-02],\n",
      "          [-7.0910e-03, -3.6418e-02, -2.4292e-03, -3.5275e-02,  2.2273e-02],\n",
      "          [ 4.1999e-02, -7.8097e-03,  2.2685e-03,  4.2512e-03,  1.1498e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.0461e-02,  4.3389e-02, -2.1327e-02, -3.9136e-02,  2.8452e-02],\n",
      "          [ 2.1613e-02,  2.8476e-04,  2.7062e-02,  1.2318e-02,  1.1260e-02],\n",
      "          [-2.2406e-02, -4.1989e-02, -1.3635e-02,  1.6544e-02, -8.1459e-03],\n",
      "          [-4.3236e-02,  3.1097e-02,  2.6870e-02, -3.0138e-02, -2.5056e-02],\n",
      "          [-1.4077e-02, -3.2987e-02,  2.2196e-02,  3.0242e-02, -1.8014e-02]],\n",
      "\n",
      "         [[ 3.5189e-02,  1.7524e-02, -3.9671e-02, -8.7916e-03, -4.2864e-02],\n",
      "          [ 2.1548e-02,  7.5868e-03,  3.4142e-02,  1.9082e-02, -1.7774e-02],\n",
      "          [ 3.8975e-02, -3.3543e-02,  2.3020e-02, -9.6040e-03, -2.5798e-02],\n",
      "          [-2.0809e-02, -2.4896e-02, -6.3381e-03,  5.3139e-03,  5.0809e-03],\n",
      "          [-3.2798e-02,  2.0439e-02, -4.4966e-03,  2.6505e-02, -1.7710e-02]],\n",
      "\n",
      "         [[-4.1458e-02, -4.4721e-02, -2.2648e-02, -1.0781e-02,  1.2289e-02],\n",
      "          [ 4.0889e-02, -3.0820e-02,  8.3110e-03, -5.8248e-03,  7.0851e-03],\n",
      "          [ 3.9048e-02, -3.1074e-02,  1.6316e-02,  7.5090e-03,  1.7955e-02],\n",
      "          [-2.9556e-02, -1.5781e-02,  3.2613e-04, -2.0857e-02, -2.0542e-02],\n",
      "          [ 3.5040e-02, -1.3361e-02, -3.9719e-02, -8.5991e-03,  3.4452e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8718e-02,  4.0898e-02,  3.2574e-02,  2.5493e-02, -3.3432e-02],\n",
      "          [-2.9989e-02, -1.2092e-02, -1.1542e-02, -2.2710e-02, -8.3420e-03],\n",
      "          [-3.7561e-02,  4.2335e-02,  2.4022e-02,  4.4437e-02, -3.6390e-02],\n",
      "          [ 2.1998e-03,  1.1302e-02,  4.9880e-03, -1.8276e-02, -1.3512e-02],\n",
      "          [ 1.7813e-02, -6.0059e-03, -7.0114e-03, -1.6869e-02, -3.2462e-02]],\n",
      "\n",
      "         [[-4.2026e-02, -4.1065e-02,  1.8655e-02, -2.3855e-02,  9.4112e-03],\n",
      "          [-1.4223e-02, -1.9710e-02, -7.6004e-03,  3.6704e-02, -2.0686e-02],\n",
      "          [ 1.2370e-04, -3.2572e-02,  2.4876e-02, -2.9067e-02,  9.4194e-03],\n",
      "          [ 8.8302e-03, -6.4396e-03, -2.5955e-02,  3.1174e-02,  4.2046e-03],\n",
      "          [-1.2058e-02, -1.2151e-02, -9.9842e-03, -3.8257e-02, -2.9261e-02]],\n",
      "\n",
      "         [[-3.9991e-02,  3.2322e-02,  3.1642e-02, -5.9339e-03, -1.3012e-05],\n",
      "          [-1.5282e-03, -2.8790e-02,  6.7417e-03, -3.0357e-02,  2.0446e-02],\n",
      "          [-9.5183e-03,  3.0481e-02,  3.5317e-02, -1.6482e-02,  6.3584e-03],\n",
      "          [ 4.3060e-02, -2.4148e-03, -2.0467e-02,  1.0661e-02,  7.4582e-03],\n",
      "          [ 4.2170e-02, -2.4056e-02, -4.3746e-02,  2.3184e-02,  3.6908e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.4432e-02, -3.7843e-03, -4.6003e-03,  4.4443e-02, -2.3622e-02],\n",
      "          [-2.4483e-02, -2.6114e-02, -3.2226e-02, -1.6439e-02,  2.9676e-02],\n",
      "          [ 1.1498e-02,  2.9465e-02,  1.5104e-02,  1.8762e-02, -1.4431e-02],\n",
      "          [ 1.2360e-02,  1.7942e-02, -1.0620e-02,  3.4793e-02,  3.6029e-02],\n",
      "          [ 3.1906e-02, -2.6186e-02, -2.9967e-02,  1.5663e-02, -2.8507e-02]],\n",
      "\n",
      "         [[ 3.7381e-02, -3.5613e-02, -4.3333e-02, -3.5906e-02,  1.3798e-02],\n",
      "          [-2.8544e-02, -4.1798e-03,  5.5314e-03, -4.3969e-02,  3.4378e-03],\n",
      "          [ 3.7768e-02,  1.7518e-02, -3.8912e-02,  2.5524e-02, -2.2804e-02],\n",
      "          [ 2.0752e-02,  4.7093e-03,  4.3675e-02,  4.6128e-03,  4.9527e-03],\n",
      "          [-4.4236e-02, -3.5493e-02,  2.5346e-02,  3.5932e-02,  2.1445e-03]],\n",
      "\n",
      "         [[-1.0124e-02,  4.1806e-02,  4.8016e-03,  2.6030e-02, -3.0002e-02],\n",
      "          [ 2.7141e-03,  3.0706e-02,  3.6998e-02, -3.2297e-02, -1.4428e-02],\n",
      "          [-2.5106e-02, -4.4642e-02, -1.1577e-02,  2.7181e-02, -1.7743e-02],\n",
      "          [ 3.1060e-02,  2.9679e-02, -2.6750e-02,  1.0912e-03, -2.2941e-02],\n",
      "          [-4.4576e-02, -1.0829e-02,  7.8845e-03, -2.1282e-02,  1.8085e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2095e-02, -2.7988e-02, -1.9497e-02, -4.1454e-02, -3.2322e-02],\n",
      "          [ 1.5086e-02,  2.3213e-02, -3.7521e-02,  9.3736e-03,  4.0418e-02],\n",
      "          [-1.1191e-02, -3.8594e-02,  1.1963e-02,  5.0798e-03, -3.2523e-02],\n",
      "          [ 4.1783e-02,  3.7601e-02, -3.2872e-02,  2.0249e-02, -3.2584e-02],\n",
      "          [-3.5485e-02,  3.4618e-02,  3.8855e-02,  2.9106e-02,  3.2218e-02]],\n",
      "\n",
      "         [[ 3.8220e-02,  6.2312e-03,  3.9123e-02,  3.6974e-02, -1.5361e-03],\n",
      "          [ 1.6493e-02, -7.3583e-04, -7.0431e-03,  3.4580e-02, -3.5166e-02],\n",
      "          [-3.4573e-03, -1.6072e-02, -4.3976e-02, -5.7197e-03, -4.4163e-02],\n",
      "          [-2.6196e-02, -3.2702e-02, -3.0035e-02,  9.3687e-03,  2.6753e-02],\n",
      "          [ 1.3270e-02,  2.7843e-02, -1.3700e-02,  1.8389e-02, -2.5897e-02]],\n",
      "\n",
      "         [[ 2.0514e-04, -4.2135e-02,  4.1252e-02,  3.5384e-02,  3.1071e-02],\n",
      "          [ 1.1242e-02,  2.7904e-02, -3.6259e-02, -1.5498e-02, -5.9346e-03],\n",
      "          [-1.2055e-02, -2.9175e-02, -3.7856e-03,  2.4145e-02,  1.9496e-02],\n",
      "          [ 3.1472e-02, -3.9056e-02,  3.0415e-02, -1.6157e-02,  3.3769e-02],\n",
      "          [-3.4448e-02, -2.8708e-02,  2.0290e-02, -3.0550e-02, -1.2049e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.4167e-03,  1.2487e-02,  6.8945e-03,  2.3716e-02,  1.8470e-02],\n",
      "          [ 1.2310e-02,  3.7612e-02,  1.0154e-02,  5.6380e-03, -3.4781e-02],\n",
      "          [ 3.6323e-02,  9.2098e-03, -1.4565e-02, -1.9473e-02,  1.0324e-02],\n",
      "          [ 8.6034e-03, -1.6509e-02,  2.6693e-02,  6.4851e-03, -1.5491e-02],\n",
      "          [ 2.3108e-03, -2.8868e-02,  2.7698e-02, -6.8609e-03,  1.2103e-02]],\n",
      "\n",
      "         [[ 1.3811e-02, -4.3270e-02,  1.9109e-02,  4.0640e-02, -2.1701e-02],\n",
      "          [-4.0591e-02,  3.2545e-02, -2.6350e-02, -3.8722e-02,  4.1649e-02],\n",
      "          [-2.0928e-02,  3.3010e-02, -2.5111e-02, -1.6677e-02,  5.7598e-03],\n",
      "          [ 2.4855e-02,  4.4331e-02, -9.6342e-03,  1.4407e-02,  4.0898e-02],\n",
      "          [-1.5392e-02,  4.0590e-02,  4.0663e-02, -1.5612e-02,  2.4041e-02]],\n",
      "\n",
      "         [[ 3.4096e-02, -1.4960e-02,  3.1876e-02,  3.7550e-02, -1.3701e-02],\n",
      "          [-2.8943e-02,  2.6434e-02,  1.1098e-02,  2.7304e-02, -3.5506e-02],\n",
      "          [ 3.4159e-02,  1.7021e-02,  3.7310e-02,  1.6198e-02, -2.6546e-02],\n",
      "          [ 3.0374e-02, -2.2612e-02,  4.0102e-03,  8.9641e-03, -2.9057e-02],\n",
      "          [ 2.9669e-02, -3.3616e-02, -3.9466e-02,  2.1928e-02, -2.3351e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 4.0953e-02, -1.1547e-02,  3.3973e-02, -1.3607e-02, -2.6764e-02],\n",
      "          [-2.1932e-02,  4.2268e-03,  1.3765e-02,  4.0112e-04, -4.2857e-02],\n",
      "          [-2.4520e-02,  2.2273e-03, -2.0457e-02, -2.6133e-02,  1.4675e-02],\n",
      "          [ 8.2726e-03,  3.8980e-02, -3.8073e-03, -4.3362e-02,  2.4257e-02],\n",
      "          [-4.1483e-02, -3.3887e-03,  3.0415e-02, -1.3907e-02,  1.6080e-03]],\n",
      "\n",
      "         [[-4.3317e-02, -1.7597e-02, -2.5113e-02, -2.5067e-02, -2.4810e-02],\n",
      "          [ 4.4042e-02, -1.8370e-03, -1.7247e-02,  2.0290e-02,  1.7203e-02],\n",
      "          [ 1.0024e-02, -1.2317e-02, -2.1493e-02, -9.4543e-03, -4.2055e-02],\n",
      "          [ 3.9198e-02,  3.2961e-02, -4.1909e-03, -4.2438e-02, -3.7351e-02],\n",
      "          [ 3.7378e-02,  1.2404e-03,  2.2202e-02, -3.4799e-02,  1.8368e-02]],\n",
      "\n",
      "         [[ 2.6159e-02,  1.6736e-02, -3.0849e-03, -2.5340e-02, -3.1167e-02],\n",
      "          [ 3.7961e-02, -7.2715e-03,  3.3758e-03,  9.2417e-03, -8.8790e-03],\n",
      "          [ 3.2906e-02, -2.2901e-02, -3.2244e-02, -2.9175e-02,  2.8445e-02],\n",
      "          [-8.1451e-03, -7.7295e-03, -8.1573e-04, -2.2556e-02, -1.5603e-02],\n",
      "          [-1.0574e-02, -3.3005e-02, -2.3966e-02,  4.2625e-02,  2.6266e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.6924e-02, -2.9631e-02, -3.8005e-02,  4.0704e-02, -9.6485e-03],\n",
      "          [-2.0882e-03,  2.3271e-02, -2.8514e-02,  3.8831e-02, -3.1811e-02],\n",
      "          [ 3.7576e-02,  3.0217e-02, -2.6724e-02, -1.6938e-02, -7.1247e-03],\n",
      "          [ 2.4936e-02,  6.2051e-03,  1.3668e-02,  2.2062e-02,  4.4585e-03],\n",
      "          [ 2.9225e-02,  1.3459e-02, -4.8084e-03, -2.8927e-02, -3.2799e-02]],\n",
      "\n",
      "         [[-4.2523e-02, -2.7683e-02,  1.6191e-02, -3.0298e-02, -2.3739e-02],\n",
      "          [-1.5509e-02, -1.3375e-02, -1.9374e-02, -4.1933e-02,  3.0163e-03],\n",
      "          [-4.0375e-02, -1.2790e-02,  2.8338e-02, -4.2313e-02, -2.2660e-02],\n",
      "          [ 4.0614e-02, -1.8941e-02,  4.3598e-02,  1.7177e-02, -3.6530e-02],\n",
      "          [-5.2340e-03,  4.1755e-02, -3.7085e-02,  1.5342e-02,  3.4470e-02]],\n",
      "\n",
      "         [[ 1.7652e-02, -6.2614e-03, -2.8164e-02, -2.7794e-02,  2.3085e-02],\n",
      "          [-1.9810e-02,  1.5743e-02,  8.2491e-03, -1.8709e-02, -2.6920e-03],\n",
      "          [-1.3057e-02,  3.3608e-02,  3.1450e-02,  2.4654e-02, -8.5033e-04],\n",
      "          [ 3.7607e-02, -4.0429e-02,  3.9946e-02, -2.4350e-03,  3.4725e-02],\n",
      "          [ 1.6533e-03,  3.6112e-02, -1.8197e-02, -1.6791e-02,  9.6710e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3815e-02, -4.3881e-02,  2.5082e-02,  2.8757e-02, -3.4939e-02],\n",
      "          [-9.3659e-03,  1.1848e-02,  2.7175e-02, -2.6192e-02,  7.1721e-03],\n",
      "          [ 6.9282e-03, -4.3855e-02,  3.9385e-02,  4.3917e-02, -1.1575e-02],\n",
      "          [ 1.1366e-02,  3.0132e-02,  3.5215e-02, -2.1537e-02,  1.8376e-02],\n",
      "          [-9.9400e-03,  2.8872e-02,  2.5866e-02, -4.0373e-03,  3.6834e-02]],\n",
      "\n",
      "         [[-1.1656e-02,  1.8995e-03,  1.7686e-02, -3.3404e-02, -3.7536e-03],\n",
      "          [-4.4389e-02,  1.2355e-02, -1.5316e-03, -1.9962e-02, -2.6512e-02],\n",
      "          [-2.7012e-02,  1.5893e-02,  2.9425e-02, -2.3863e-03,  2.6287e-02],\n",
      "          [-2.9424e-02, -4.2027e-02,  4.3816e-02,  1.6261e-02,  2.1690e-02],\n",
      "          [ 7.4778e-03, -1.7690e-02,  7.5269e-03,  3.3092e-02, -2.6336e-02]],\n",
      "\n",
      "         [[-2.9072e-02,  4.1669e-02, -1.6351e-02,  7.2482e-03,  3.3646e-02],\n",
      "          [-2.2819e-02, -3.0475e-02, -1.1503e-03, -3.4701e-02, -1.4107e-02],\n",
      "          [ 3.1843e-02, -3.1179e-02, -4.2339e-02,  2.9680e-02,  7.0257e-03],\n",
      "          [ 5.2478e-03, -1.7860e-02, -8.7782e-03, -2.9604e-02, -2.0956e-02],\n",
      "          [ 1.1313e-02,  3.3430e-03, -1.0836e-02, -2.2434e-02,  2.5486e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.1461e-03, -4.2713e-02, -3.8864e-03,  2.3578e-02, -1.9593e-02],\n",
      "          [-4.6950e-04,  3.9679e-02, -1.2723e-02, -2.1067e-02,  4.3053e-04],\n",
      "          [-2.5832e-02,  2.3964e-02, -4.0862e-02, -8.8074e-03, -6.2770e-03],\n",
      "          [-4.2273e-02,  4.4261e-02,  4.4206e-03, -2.5448e-02, -1.1990e-03],\n",
      "          [ 2.4132e-02, -3.7815e-03, -1.7831e-02,  1.0161e-02, -2.3032e-02]],\n",
      "\n",
      "         [[ 4.0706e-03,  2.5964e-02, -8.0237e-03,  2.5611e-02,  1.8484e-02],\n",
      "          [-1.8247e-02,  3.0307e-03, -8.1729e-03, -3.8596e-02,  4.2887e-02],\n",
      "          [ 5.7422e-03,  2.0368e-02,  2.8717e-02, -5.9357e-04, -1.8002e-02],\n",
      "          [-1.4563e-02,  3.6213e-02,  3.9723e-02,  4.3584e-02,  1.8948e-02],\n",
      "          [ 1.0004e-03,  3.6139e-02,  3.5592e-02, -5.9603e-03, -9.4833e-03]],\n",
      "\n",
      "         [[-3.7167e-02,  3.3457e-02,  1.2867e-02, -2.8912e-02,  3.2633e-02],\n",
      "          [ 6.3298e-03,  3.5183e-02, -2.6982e-02,  4.3587e-02,  1.7368e-02],\n",
      "          [ 1.4262e-02,  7.9296e-03, -3.6342e-02,  2.6621e-04,  1.6086e-02],\n",
      "          [ 2.1234e-02, -3.0982e-02,  2.9069e-02,  4.8804e-04,  3.9956e-02],\n",
      "          [-6.7350e-03,  1.2938e-02,  2.3108e-03, -2.5764e-02, -2.3077e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8956e-02, -2.6487e-02, -1.8474e-02,  2.2925e-02,  1.9410e-02],\n",
      "          [ 3.9859e-03,  7.7058e-03,  1.7444e-02,  3.0700e-02,  1.8142e-02],\n",
      "          [ 2.7865e-02,  3.2761e-02, -1.6124e-02,  4.2691e-02,  4.0797e-02],\n",
      "          [ 3.6220e-02,  1.2980e-02, -3.8976e-02,  2.7678e-03, -4.3314e-02],\n",
      "          [-9.9181e-03, -3.5585e-02,  8.7266e-03,  1.0556e-03,  3.0100e-02]],\n",
      "\n",
      "         [[ 9.3734e-03,  3.7171e-02,  2.5876e-02,  3.5375e-02,  1.4917e-02],\n",
      "          [ 7.4767e-03,  2.6579e-02, -1.8579e-03, -1.0759e-02,  1.9146e-04],\n",
      "          [-2.4407e-02, -2.3145e-02, -2.5917e-02, -2.8884e-02,  1.1678e-02],\n",
      "          [ 3.7719e-02, -1.2466e-02,  2.1144e-02, -1.5490e-03, -2.4289e-02],\n",
      "          [ 3.6927e-02, -2.8550e-02, -2.1144e-02,  2.8642e-02,  2.4259e-02]],\n",
      "\n",
      "         [[-3.7533e-02,  1.9611e-02,  1.6591e-03,  1.6933e-02,  1.9740e-02],\n",
      "          [ 3.7165e-02, -3.9054e-02, -2.3220e-02, -2.4832e-03,  3.2987e-02],\n",
      "          [ 1.4586e-02, -8.9109e-03, -4.0359e-02, -3.0373e-02, -3.3640e-03],\n",
      "          [ 1.7384e-02,  1.2563e-02, -1.1410e-02,  4.1225e-02, -9.3339e-03],\n",
      "          [-1.2041e-03, -2.7765e-02,  2.5744e-02,  1.3420e-02,  1.5054e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.1256e-03, -2.2631e-02,  1.2957e-02, -9.3002e-04, -2.5643e-02],\n",
      "          [ 2.1163e-02,  2.3251e-02, -2.9694e-02, -9.4985e-03, -3.6872e-02],\n",
      "          [ 1.1296e-03, -1.0955e-02, -4.0841e-04, -2.7520e-02, -1.0978e-02],\n",
      "          [ 9.2172e-03,  3.4064e-02,  7.9385e-03,  1.9910e-02, -3.9169e-02],\n",
      "          [-2.4043e-02,  1.5657e-02,  4.2232e-02,  1.9596e-02,  4.2769e-02]],\n",
      "\n",
      "         [[ 2.1875e-02,  4.2287e-02, -3.6824e-02,  3.4513e-02,  3.1864e-03],\n",
      "          [ 1.6315e-03, -2.9226e-02,  3.3589e-02, -1.5118e-02,  4.4482e-02],\n",
      "          [-4.2778e-02, -3.6028e-03,  2.7846e-03, -3.4958e-03,  3.8550e-02],\n",
      "          [ 9.3501e-03, -3.1036e-02, -3.7879e-02, -1.8935e-02, -7.0862e-03],\n",
      "          [-4.1997e-02,  2.1595e-02, -1.5871e-02, -2.7355e-02, -3.9701e-02]],\n",
      "\n",
      "         [[-2.1617e-02,  8.5151e-03, -3.1821e-02,  3.6985e-02,  4.1379e-02],\n",
      "          [ 4.1893e-02, -3.3653e-02, -3.8989e-02, -2.2553e-02, -4.4292e-02],\n",
      "          [ 2.0266e-02,  1.3830e-02,  3.3720e-02, -1.9139e-02,  3.6951e-02],\n",
      "          [-2.8938e-02, -1.8229e-02, -3.7877e-02, -4.1179e-02, -1.2504e-02],\n",
      "          [ 1.0357e-02,  2.7604e-03, -3.9385e-02, -1.9687e-02,  3.8179e-02]]]])), ('conv2.bias', tensor([ 0.0120,  0.0236,  0.0133,  0.0248, -0.0437, -0.0104, -0.0070, -0.0158,\n",
      "         0.0093, -0.0122,  0.0254, -0.0124, -0.0281, -0.0392, -0.0057, -0.0380,\n",
      "        -0.0437, -0.0298, -0.0256, -0.0432,  0.0419,  0.0388,  0.0215,  0.0193,\n",
      "        -0.0009, -0.0181,  0.0394,  0.0129,  0.0178,  0.0238, -0.0358,  0.0324,\n",
      "        -0.0034,  0.0390, -0.0216,  0.0103,  0.0338,  0.0317, -0.0048,  0.0243])), ('FC1.weight', tensor([[-0.0103,  0.0107, -0.0054,  ...,  0.0394, -0.0370, -0.0011],\n",
      "        [ 0.0070,  0.0366,  0.0196,  ...,  0.0022, -0.0336,  0.0262],\n",
      "        [-0.0279,  0.0275, -0.0142,  ..., -0.0196,  0.0237, -0.0238],\n",
      "        ...,\n",
      "        [-0.0261,  0.0224, -0.0076,  ..., -0.0100, -0.0168,  0.0085],\n",
      "        [ 0.0246, -0.0008, -0.0115,  ..., -0.0019,  0.0261, -0.0371],\n",
      "        [-0.0203, -0.0022,  0.0371,  ..., -0.0306,  0.0394, -0.0347]])), ('FC1.bias', tensor([-0.0177,  0.0075,  0.0072, -0.0213, -0.0112,  0.0355, -0.0078, -0.0040,\n",
      "         0.0114,  0.0246, -0.0358, -0.0157,  0.0346, -0.0250,  0.0277,  0.0136,\n",
      "        -0.0341, -0.0164,  0.0014, -0.0368,  0.0084,  0.0266,  0.0173,  0.0305,\n",
      "         0.0348, -0.0111,  0.0282, -0.0392, -0.0328,  0.0320,  0.0119,  0.0311,\n",
      "         0.0366, -0.0159, -0.0185, -0.0089, -0.0015, -0.0198,  0.0271,  0.0227,\n",
      "         0.0049,  0.0368, -0.0119, -0.0048, -0.0330,  0.0102, -0.0101, -0.0388,\n",
      "         0.0056, -0.0199, -0.0334, -0.0178,  0.0187,  0.0352, -0.0005,  0.0158,\n",
      "        -0.0341,  0.0322, -0.0154,  0.0224, -0.0368, -0.0085,  0.0285, -0.0298])), ('Classifier.weight', tensor([[-6.2133e-02, -6.2272e-02,  1.0581e-02,  3.3395e-02,  9.6249e-02,\n",
      "         -7.5329e-02, -4.0724e-02,  7.4814e-02, -1.2875e-02, -1.0865e-01,\n",
      "         -1.2473e-01,  1.0716e-02,  3.6731e-02, -6.6780e-02, -9.4780e-02,\n",
      "         -1.4961e-02, -8.6589e-02,  9.2885e-02, -9.4180e-02, -1.1895e-01,\n",
      "          7.9360e-03,  3.5811e-02,  4.6549e-02, -3.4710e-02,  4.2602e-02,\n",
      "         -1.0339e-01, -7.7976e-02,  1.0901e-01,  6.3543e-02, -1.1593e-01,\n",
      "         -4.7964e-02, -8.6630e-02,  3.3127e-02, -2.4071e-02, -2.1629e-02,\n",
      "          5.3138e-02,  9.6184e-02, -9.3009e-02, -3.2825e-02,  4.3509e-02,\n",
      "         -6.5717e-03, -7.7798e-02,  4.4283e-02, -2.7093e-02,  6.9088e-02,\n",
      "          4.7364e-02,  3.3881e-02,  8.1533e-02,  1.0377e-01, -3.7900e-02,\n",
      "         -1.0187e-01,  1.4216e-03, -3.4794e-03, -7.9080e-02,  5.3618e-02,\n",
      "          4.1574e-02, -4.8720e-02, -4.6433e-02, -5.8512e-02,  3.3293e-02,\n",
      "          3.0477e-03, -1.0631e-01,  3.8918e-02,  7.2062e-02],\n",
      "        [-2.2148e-02,  7.6835e-02,  1.2339e-01, -2.8344e-02, -6.8618e-02,\n",
      "         -7.5910e-02,  6.3335e-02,  1.0298e-01,  1.1567e-01,  5.9967e-02,\n",
      "          9.4067e-02,  7.2631e-02, -9.1414e-02, -9.4290e-02,  8.6427e-02,\n",
      "          8.1874e-02,  5.5170e-02,  7.5817e-02, -1.3250e-02,  1.5146e-02,\n",
      "         -1.0799e-01,  4.6477e-02,  1.0140e-01,  3.5740e-02,  1.5483e-02,\n",
      "          8.5783e-02, -2.5903e-02, -9.8266e-02,  1.0277e-01, -8.3874e-02,\n",
      "         -4.6820e-02, -9.1400e-02,  4.9160e-02, -1.1907e-01, -9.3755e-02,\n",
      "          1.1624e-01,  3.3229e-02, -6.1489e-02,  1.0074e-01, -8.9472e-02,\n",
      "          1.0968e-02, -1.2142e-01, -9.5316e-02,  7.3525e-02, -3.6693e-02,\n",
      "          4.0786e-02, -4.9054e-02,  1.0399e-01,  7.6522e-02,  8.3722e-02,\n",
      "         -3.4615e-02,  2.1022e-02, -9.8485e-02, -7.0675e-02,  3.9841e-04,\n",
      "         -1.0793e-01,  9.8218e-02,  9.3227e-02, -8.4971e-02, -1.0358e-01,\n",
      "          6.8414e-02,  3.2216e-02, -1.0919e-02,  3.6888e-02],\n",
      "        [ 1.0982e-01, -1.5846e-02,  9.5286e-02, -6.4093e-02, -9.1117e-02,\n",
      "         -1.0455e-01, -5.2628e-02,  1.7547e-03, -1.1184e-01,  5.3478e-02,\n",
      "          8.3089e-05,  1.0046e-01,  5.8300e-02, -7.0947e-02, -8.4171e-02,\n",
      "          4.7436e-03,  1.4596e-02, -3.2687e-02, -2.2444e-02, -2.4026e-02,\n",
      "         -7.5626e-02,  1.0164e-02, -1.1140e-01, -7.2212e-02,  1.1718e-01,\n",
      "          5.2905e-03, -7.6884e-03, -3.2904e-02, -1.0063e-01, -5.7856e-02,\n",
      "         -1.1850e-01,  8.9449e-02, -9.2427e-02,  5.3578e-02,  6.9262e-02,\n",
      "         -1.2351e-01, -2.6625e-02, -2.9200e-02, -4.8459e-02, -4.3926e-02,\n",
      "         -1.2253e-01,  5.9609e-02, -7.3218e-03, -7.8142e-02, -6.8352e-02,\n",
      "          2.6867e-02, -3.8262e-02, -6.3987e-03,  1.1993e-01, -7.0077e-02,\n",
      "          8.3674e-02, -2.0878e-02, -3.4622e-02, -5.0883e-02,  1.2376e-01,\n",
      "         -6.8725e-03,  1.0554e-01,  6.3598e-02, -6.1371e-02,  4.6018e-02,\n",
      "         -3.4872e-02,  6.0996e-04,  3.8600e-02,  7.2180e-02],\n",
      "        [-1.0637e-01, -4.3416e-02,  2.5514e-03,  4.1349e-02, -8.4570e-02,\n",
      "         -5.2733e-02, -1.1057e-01,  6.2220e-02, -1.2473e-01, -6.5054e-02,\n",
      "          1.9529e-03, -8.2182e-02,  9.4625e-02, -1.1623e-01, -1.3428e-02,\n",
      "         -1.2341e-02,  3.2545e-02,  6.2821e-02, -1.2326e-01,  1.1617e-03,\n",
      "         -9.4986e-02,  1.1513e-01,  9.5846e-02, -1.1616e-01,  1.1112e-01,\n",
      "         -6.6501e-02,  3.1372e-03,  6.1224e-02,  1.0087e-01,  9.3073e-02,\n",
      "          1.0038e-01, -1.1303e-01, -1.1949e-01, -1.1792e-01,  1.2327e-01,\n",
      "          1.2317e-01,  7.9685e-02,  6.6305e-02, -1.2226e-02,  7.8472e-03,\n",
      "         -4.1936e-02,  6.7948e-02, -1.2205e-01, -8.1529e-02, -9.4335e-02,\n",
      "          5.2313e-02,  3.4064e-02,  3.5734e-02, -1.0691e-01,  8.3955e-02,\n",
      "          1.5477e-02, -6.4639e-02,  2.6541e-02,  2.3185e-03,  1.0814e-01,\n",
      "         -5.9537e-02,  7.5446e-02, -1.8779e-02, -4.5037e-02,  1.1477e-01,\n",
      "          1.3361e-03, -1.0234e-01, -7.2833e-02, -3.3346e-02],\n",
      "        [-1.0285e-01, -1.1199e-01, -2.9652e-02,  8.4138e-02, -2.8619e-02,\n",
      "         -2.9364e-02, -1.7893e-02,  1.4538e-02,  4.5571e-03, -1.2400e-01,\n",
      "          4.0400e-02,  2.3250e-02,  8.4506e-02, -3.6459e-02, -7.6555e-02,\n",
      "          3.6329e-02,  1.4612e-02,  1.5611e-02, -8.7812e-02,  5.7551e-02,\n",
      "         -1.2928e-02, -9.4511e-02,  5.1105e-02,  1.1931e-01, -4.8613e-02,\n",
      "          1.0480e-01,  1.9648e-02,  2.2201e-02, -1.2412e-01,  1.6987e-02,\n",
      "         -1.2475e-01, -4.1978e-03,  1.1944e-01,  4.7432e-03, -7.1635e-02,\n",
      "          6.9404e-02, -8.9546e-02, -1.6954e-02, -2.7153e-03,  6.1545e-02,\n",
      "         -1.1880e-01, -1.7550e-02, -4.5168e-02,  1.0367e-01,  3.6743e-02,\n",
      "         -3.1825e-02, -1.4249e-02,  3.5978e-02,  8.1132e-02, -9.9290e-03,\n",
      "          4.3910e-02, -3.4527e-02,  2.3678e-02, -8.5550e-02,  1.0263e-01,\n",
      "          7.5927e-02,  3.1564e-03, -1.1005e-01, -1.1464e-01,  1.9373e-02,\n",
      "          7.9054e-02, -2.5820e-02, -1.0108e-01,  2.1480e-04],\n",
      "        [-4.1392e-02,  7.2128e-02, -5.1640e-02,  1.1143e-01,  5.2999e-02,\n",
      "         -6.9493e-02, -1.0225e-01, -1.3790e-02,  1.0822e-01, -3.4906e-02,\n",
      "         -8.1618e-03,  1.2087e-01, -1.1621e-01,  6.2738e-02, -3.7950e-02,\n",
      "          8.3504e-02, -4.8643e-03, -7.5812e-02,  4.3511e-02, -8.0093e-02,\n",
      "          1.7656e-02,  1.0085e-01, -5.8964e-02,  7.9382e-02, -7.4933e-02,\n",
      "         -1.1615e-01,  1.1384e-01,  1.0001e-02,  2.1179e-02, -1.2867e-02,\n",
      "          1.8329e-02,  5.2588e-02,  1.1113e-01, -9.4328e-02,  9.2901e-02,\n",
      "         -9.0719e-02,  1.0443e-01,  4.4161e-02, -6.0081e-03, -2.4290e-02,\n",
      "          1.1704e-01, -7.3116e-02, -2.3058e-02, -8.7073e-02,  7.1804e-02,\n",
      "         -2.3095e-02,  9.5341e-02,  2.8009e-02, -8.2387e-02,  1.1806e-01,\n",
      "          1.1447e-01,  3.1770e-02,  1.3475e-03,  1.1795e-01, -3.0747e-02,\n",
      "          1.1373e-01,  1.6572e-02,  4.0055e-02, -8.6993e-02, -8.4630e-02,\n",
      "         -1.2427e-01, -2.9742e-02,  1.4489e-02, -2.4654e-02],\n",
      "        [-2.0637e-02, -5.3572e-02, -8.7528e-02,  1.0848e-02,  1.4147e-02,\n",
      "          9.4614e-02, -1.0925e-01, -9.0553e-02,  1.0400e-01,  9.4696e-02,\n",
      "          2.4776e-02,  1.3724e-02,  1.1100e-01, -1.4607e-03, -7.6752e-02,\n",
      "          4.1595e-02,  3.0675e-02,  3.7949e-02, -6.6272e-02, -6.2500e-02,\n",
      "          1.1579e-02,  4.0057e-02, -1.0024e-01,  9.9711e-02,  6.0427e-02,\n",
      "          5.8880e-03, -8.3911e-02, -6.5318e-02,  1.1584e-02, -1.1909e-02,\n",
      "         -1.1969e-01, -1.0594e-01, -1.6960e-02,  3.9000e-02,  7.3891e-02,\n",
      "         -3.9883e-02, -8.0379e-02, -7.1014e-02,  5.1424e-02, -1.5569e-02,\n",
      "          2.0201e-02, -1.2440e-01, -1.0441e-01, -7.4441e-02, -9.7637e-02,\n",
      "          8.1051e-02,  1.0921e-01, -1.1514e-01,  1.2253e-01, -3.3267e-02,\n",
      "          2.0334e-02,  5.8321e-02, -7.7305e-02,  2.7207e-02, -5.7579e-02,\n",
      "         -1.1713e-01, -7.8905e-02,  6.9466e-02,  1.1185e-01, -5.4306e-02,\n",
      "         -1.0478e-01, -7.1822e-02, -7.1439e-02, -4.3177e-03],\n",
      "        [-1.1773e-01,  5.1136e-02, -1.0455e-02, -1.2385e-01, -7.3255e-02,\n",
      "         -1.1329e-01,  1.0837e-01,  8.6840e-02, -6.2044e-02, -4.5037e-04,\n",
      "         -6.8704e-02, -1.1895e-01,  6.3130e-03,  1.2095e-01, -9.1850e-02,\n",
      "         -7.9120e-02, -6.9457e-02,  8.5917e-02,  9.6364e-02, -1.1848e-01,\n",
      "          8.5789e-02, -8.9267e-02, -7.1315e-02, -9.8870e-02,  9.8822e-02,\n",
      "         -1.5462e-02,  1.0009e-01, -3.8654e-02, -9.7655e-02,  7.8288e-02,\n",
      "         -6.1045e-02, -5.5743e-02, -8.9243e-02, -2.6082e-03, -3.4390e-02,\n",
      "          6.4670e-02,  2.4969e-02,  2.2614e-02, -9.7967e-02,  7.5154e-02,\n",
      "          3.9894e-02,  3.3714e-03, -4.2167e-02,  1.8466e-02, -9.7243e-02,\n",
      "          8.9806e-02,  8.1136e-02, -4.4571e-02, -6.9524e-02, -1.5071e-04,\n",
      "         -4.1284e-02,  8.9980e-02, -4.8320e-03, -2.0871e-02,  5.3480e-02,\n",
      "         -9.6629e-02, -7.2480e-02,  3.4107e-02, -1.1963e-02,  1.2167e-01,\n",
      "          1.0982e-01, -4.6458e-02, -9.9133e-02, -1.2328e-01],\n",
      "        [-7.5883e-02,  7.9621e-02, -9.4355e-02, -9.0674e-02,  9.8871e-02,\n",
      "         -1.8233e-02, -1.9341e-02, -4.0194e-02,  4.0651e-02,  1.0770e-01,\n",
      "          2.2996e-02, -1.2347e-01,  3.1485e-02,  7.8287e-03, -8.3214e-02,\n",
      "          5.0351e-05,  8.5187e-02, -6.4346e-02, -5.1050e-02, -7.6102e-02,\n",
      "         -2.4359e-02,  6.6247e-02,  4.5224e-02,  1.6885e-02,  3.6119e-02,\n",
      "         -5.3640e-02, -4.0056e-02, -1.0410e-01,  1.1205e-01, -6.2732e-02,\n",
      "          1.0992e-01,  3.6288e-02,  1.0600e-01,  7.6881e-02, -1.1290e-01,\n",
      "          5.2147e-02,  1.2228e-01,  8.2475e-02, -2.8487e-02, -1.1459e-01,\n",
      "          3.8395e-02,  6.1171e-02,  3.9259e-02,  9.5310e-02,  7.6205e-02,\n",
      "         -1.8623e-02,  2.3270e-02, -9.7295e-02,  2.6198e-02, -2.6021e-02,\n",
      "         -9.8390e-02, -9.1441e-02, -3.4750e-02, -7.2980e-02, -1.0324e-01,\n",
      "         -1.1167e-01, -7.0088e-02,  2.8839e-02,  5.3089e-02, -9.7051e-02,\n",
      "          1.1039e-01,  1.1891e-01,  1.2491e-01, -6.5700e-03],\n",
      "        [ 1.1428e-01, -1.2262e-03,  6.8175e-02,  1.9307e-02,  1.1129e-01,\n",
      "         -5.6403e-02,  1.1673e-01,  6.5748e-02, -4.4846e-02, -5.2633e-02,\n",
      "          1.2320e-01,  6.1122e-02,  1.1717e-01, -7.8433e-02,  1.0285e-01,\n",
      "         -3.9683e-03, -8.9846e-02, -1.1500e-01, -5.0992e-02, -2.8911e-02,\n",
      "         -4.7176e-02, -3.2511e-02, -7.2798e-03, -1.1873e-01, -1.1386e-01,\n",
      "          8.1453e-03,  6.0130e-02,  2.2767e-02, -7.8238e-02,  5.7371e-02,\n",
      "         -6.6063e-02,  9.8519e-02, -5.5530e-02, -8.8509e-02, -2.5195e-02,\n",
      "         -4.1998e-02, -7.6543e-02, -7.5583e-02, -7.8934e-03,  2.3807e-03,\n",
      "         -9.1539e-02, -1.1275e-01,  2.4790e-02, -6.9458e-03,  2.3733e-02,\n",
      "          1.0688e-01, -1.1544e-01, -6.1666e-03,  5.2810e-02,  9.2844e-02,\n",
      "         -7.9744e-02,  8.2605e-02, -9.5951e-02,  3.9292e-03,  1.0608e-01,\n",
      "          1.0757e-01, -1.3307e-02, -2.7267e-02, -1.9096e-02,  8.5673e-02,\n",
      "         -1.0131e-01,  9.5854e-02, -6.9848e-02,  1.1406e-02]])), ('Classifier.bias', tensor([-0.1033,  0.0132, -0.0923,  0.0567, -0.0239,  0.0016, -0.0381, -0.0868,\n",
      "         0.0222, -0.0740]))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e4c09d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = './MNIST/model/model_state_dict.pt'\n",
    "torch.save(model.state_dict(), FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "65276a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "06e11009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1650'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ceadcf",
   "metadata": {},
   "source": [
    "### print model weight\n",
    "#### pytorch weight shape : out_ch, in_ch, height, width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1a18c41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1656285673379898\n",
      "odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'FC1.weight', 'FC1.bias', 'Classifier.weight', 'Classifier.bias'])\n"
     ]
    }
   ],
   "source": [
    "# for param in model.parameters():\n",
    "#     print((param.data))\n",
    "or_dict = model.state_dict()\n",
    "print(float(or_dict['conv1.weight'][0][0][0][0]))\n",
    "#print(model.state_dict())\n",
    "# for key, value in or_dict.iteritems() :\n",
    "#     print(key)\n",
    "print(or_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6bd47d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "layer shape =  torch.Size([20, 1, 5, 5])\n",
      "conv1.weight\n",
      "layer shape =  torch.Size([20, 1, 5, 5])\n",
      "(0.165628567337990), (0.063333615660667), (-0.047992274165154), (-0.022682860493660), (-0.060128718614578), (-0.041119530797005), (-0.090242676436901), (0.082591757178307), (-0.108271837234497), (-0.151852637529373), (0.085584983229637), (0.170022323727608), (0.157529726624489), (0.085148587822914), (0.193555638194084), (-0.132670596241951), (-0.104478739202023), (0.028872132301331), (-0.064906805753708), (-0.086201690137386), (0.130697891116142), (0.014237478375435), (0.182219997048378), (-0.013657733798027), (-0.037669971585274), (-0.001960903406143), (0.094502106308937), (-0.062343269586563), (-0.037039324641228), (0.029607132077217), (0.093575254082680), (-0.044024273753166), (0.182707920670509), (-0.149492263793945), (-0.100583270192146), (0.123966351151466), (-0.044526189565659), (-0.036120966076851), (0.030935361981392), (0.165695562958717), (-0.153744339942932), (-0.157361671328545), (-0.050951510667801), (0.060302868485451), (-0.064846798777580), (-0.193713024258614), (0.014333456754684), (0.067919269204140), (-0.178761288523674), (0.011650770902634), (-0.160429477691650), (0.082259550690651), (-0.173552542924881), (0.032294481992722), (-0.179087787866592), (-0.171204328536987), (0.037142351269722), (0.022420331835747), (-0.190252140164375), (0.132329091429710), (0.107135787606239), (-0.002877667546272), (0.171060636639595), (-0.092693381011486), (0.153978630900383), (0.087796315550804), (0.021993428468704), (-0.061048239469528), (0.182773545384407), (-0.172736272215843), (-0.056525662541389), (-0.069239884614944), (0.004131078720093), (-0.122116997838020), (-0.174874857068062), (0.171596065163612), (-0.083227537572384), (0.153369084000587), (-0.172038897871971), (0.166012302041054), (0.105723872780800), (0.013220027089119), (-0.079948522150517), (0.176912084221840), (0.061465755105019), (0.025813430547714), (0.175392761826515), (0.156556859612465), (0.176772132515907), (-0.178699374198914), (-0.032089680433273), (0.171935334801674), (-0.115826942026615), (0.033706218004227), (-0.018048435449600), (-0.109961204230785), (-0.025959178805351), (-0.073330879211426), (0.187819585204124), (0.171127483248711), (-0.178045347332954), (0.088047131896019), (-0.197847157716751), (0.176976934075356), (0.188104167580605), (-0.137662857770920), (-0.105524182319641), (0.023712724447250), (0.030834525823593), (-0.016457676887512), (0.158253774046898), (-0.189843520522118), (0.064550921320915), (-0.151342779397964), (-0.122350268065929), (-0.126766636967659), (-0.161708548665047), (-0.137388586997986), (-0.051656633615494), (-0.172684669494629), (0.126921787858009), (0.178575292229652), (-0.079655528068542), (-0.061568781733513), (0.060551390051842), (0.027409106492996), (0.070198550820351), (-0.036912828683853), (0.160038247704506), (-0.048500567674637), (-0.159992769360542), (-0.017900794744492), (0.101926073431969), (-0.153577417135239), (-0.058525353670120), (0.017113238573074), (-0.155690953135490), (0.110135748982430), (0.073518767952919), (0.172974839806557), (-0.139117985963821), (-0.199696213006973), (0.055870428681374), (-0.186587452888489), (0.162457123398781), (0.066238090395927), (-0.104743555188179), (0.125209257006645), (0.161156311631203), (-0.149396300315857), (-0.191439703106880), (-0.169467926025391), (0.189959421753883), (0.122028127312660), (-0.134809792041779), (-0.064939424395561), (-0.189011290669441), (0.187393948435783), (0.019346386194229), (-0.066533893346786), (-0.027736350893974), (-0.196740344166756), (0.074542477726936), (-0.139549374580383), (0.169334426522255), (0.104972854256630), (0.079476371407509), (0.147112533450127), (0.101492419838905), (0.164808705449104), (0.074986115098000), (0.067742869257927), (0.092419877648354), (0.114410802721977), (-0.157376810908318), (0.127242103219032), (0.164353504776955), (-0.150856778025627), (-0.041461855173111), (0.155276432633400), (0.015752956271172), (-0.139081209897995), (-0.172267347574234), (-0.086132980883121), (0.029797032475471), (-0.031097337603569), (0.112842842936516), (0.025346085429192), (0.102097168564796), (0.094055846333504), (-0.156238824129105), (0.118441119790077), (0.196721628308296), (0.112688079476357), (-0.097170852124691), (-0.072481542825699), (-0.000046178698540), (-0.072614952921867), (-0.008431985974312), (0.041466757655144), (-0.119633078575134), (-0.166935727000237), (0.036834076046944), (0.183368489146233), (-0.017404317855835), (-0.047769755125046), (0.048988267779350), (0.178891554474831), (0.175751492381096), (-0.095760397613049), (0.124343678355217), (-0.186006575822830), (-0.106789402663708), (-0.110974930226803), (0.155537500977516), (0.130255565047264), (0.045082494616508), (0.129488244652748), (-0.050322368741035), (-0.158227369189262), (-0.029758214950562), (0.122454300522804), (0.130833759903908), (-0.021815031766891), (0.149143233895302), (-0.059483647346497), (0.033038213849068), (-0.015985459089279), (-0.011788085103035), (0.195038303732872), (0.083116963505745), (0.159165963530540), (0.186780467629433), (-0.114409707486629), (-0.149557918310165), (-0.121640615165234), (-0.016967803239822), (0.045768857002258), (-0.128810480237007), (0.104464009404182), (0.119123116135597), (0.150325909256935), (0.165465489029884), (-0.134748548269272), (0.084438219666481), (0.086238637566566), (0.153952732682228), (-0.193141564726830), (-0.011451199650764), (-0.117148496210575), (-0.182668492197990), (-0.189300924539566), (-0.129240587353706), (-0.078227333724499), (0.094017997384071), (0.129326596856117), (-0.113582514226437), (-0.030835986137390), (0.081906720995903), (-0.186473205685616), (-0.027332946658134), (0.164685949683189), (-0.110590435564518), (0.181552067399025), (0.073056027293205), (-0.075925230979919), (0.135484620928764), (0.183533325791359), (0.048897355794907), (-0.009058833122253), (0.030224636197090), (-0.162530273199081), (0.110113993287086), (-0.108286499977112), (-0.008720993995667), (0.185671731829643), (0.168627306818962), (0.125162079930305), (0.108619585633278), (0.149290695786476), (0.180622920393944), (-0.068209409713745), (0.061977997422218), (0.106446042656898), (-0.015947580337524), (-0.115106940269470), (-0.168602734804153), (-0.125006735324860), (0.080814704298973), (0.093837007880211), (-0.165159553289413), (-0.064228609204292), (-0.132768929004669), (0.035720497369766), (0.130546465516090), (0.155818358063698), (0.077677652239799), (0.156942114233971), (-0.074648350477219), (-0.144665926694870), (-0.016549438238144), (0.088030293583870), (-0.055981189012527), (-0.073500543832779), (-0.010274678468704), (0.004037976264954), (0.020507782697678), (-0.074603155255318), (0.008180782198906), (0.126262202858925), (-0.132027149200439), (-0.175321251153946), (0.136575654149055), (0.103147342801094), (0.197142764925957), (0.146579429507256), (0.069306001067162), (-0.195512160658836), (-0.052993327379227), (0.084334656596184), (0.175875917077065), (0.129441514611244), (0.187923237681389), (-0.165127560496330), (0.113324657082558), (-0.173358902335167), (0.067713782191277), (-0.043443441390991), (-0.089800141751766), (0.094769731163979), (-0.164275482296944), (-0.174896270036697), (-0.058289289474487), (-0.156404539942741), (0.097023740410805), (0.046316474676132), (-0.181769758462906), (0.039909407496452), (0.033699348568916), (0.054655417799950), (0.083670511841774), (0.048160150647163), (0.172528043389320), (-0.052131459116936), (-0.098421029746532), (0.189593568444252), (-0.196761488914490), (-0.066171720623970), (-0.124477796256542), (0.046988248825073), (0.074131742119789), (0.027588889002800), (0.021796256303787), (0.102777525782585), (-0.127210885286331), (0.169627681374550), (-0.091216705739498), (-0.106542043387890), (-0.072683855891228), (0.129833117127419), (0.020364642143250), (-0.129353582859039), (0.120536938309669), (0.166900441050529), (-0.030022025108337), (0.027942493557930), (0.160385981202126), (-0.052421331405640), (-0.029222443699837), (-0.073076412081718), (-0.089271187782288), (-0.199693009257317), (0.195967987179756), (-0.192900285124779), (-0.147107243537903), (0.065073654055595), (0.013076096773148), (-0.034729123115540), (-0.102016665041447), (0.135392919182777), (-0.128067672252655), (-0.024477571249008), (0.085719540715218), (-0.063455700874329), (-0.055771976709366), (0.028894394636154), (0.158670142292976), (0.176719978451729), (0.077498629689217), (0.179641529917717), (0.048926621675491), (0.149205699563026), (-0.093320108950138), (-0.159210294485092), (-0.159880280494690), (-0.013346195220947), (-0.015459924936295), (0.191410526633263), (0.090655699372292), (0.155015572905540), (0.031844899058342), (-0.147859185934067), (0.052649870514870), (-0.035913154482841), (0.049999564886093), (-0.086769439280033), (0.179247096180916), (0.170673891901970), (-0.133998453617096), (0.178118750452995), (0.044329211115837), (0.174993172287941), (0.129044815897942), (0.171755328774452), (-0.076958015561104), (-0.160763904452324), (-0.083391688764095), (0.157120838761330), (0.059558525681496), (-0.054750293493271), (-0.115541219711304), (-0.145843312144279), (-0.173480466008186), (-0.031078100204468), (0.068487569689751), (0.124791666865349), (0.181096985936165), (0.079003527760506), (-0.066027954220772), (0.016490295529366), (-0.025312349200249), (-0.021234869956970), (-0.193029046058655), (0.067667171359062), (-0.053690865635872), (-0.092199921607971), (-0.026172325015068), (-0.088154695928097), (-0.029441639780998), (-0.072333574295044), (-0.168176248669624), (0.079824045300484), (-0.182159811258316), (0.004947304725647), (-0.022388383746147), (-0.009344145655632), (0.041457131505013), (0.105421617627144), (-0.005936712026596), (-0.026312977075577), (0.181532159447670), (-0.190257117152214), (0.128601059317589), (-0.169957682490349), (0.050832137465477), (0.000421851873398), (-0.055765673518181), (-0.044444367289543), (0.064925327897072), (-0.117853663861752), (0.146689280867577), (-0.143780261278152), (0.171826556324959), (0.048844009637833), (-0.097200274467468), (0.135174050927162), (-0.052775099873543), (0.132842704653740), (0.040034458041191), (-0.013820245862007), (-0.156607672572136), (-0.168667271733284), (-0.176558241248131), (0.158748552203178), (-0.099216058850288), (-0.126441389322281), (-0.152743414044380), (-0.098067335784435), (-0.133139446377754), (-0.110756419599056), (-0.187242314219475), (0.176071867346764), (0.169357731938362), (0.164534494280815), (0.066447451710701), (0.128146395087242), (-0.085984759032726), (0.088394060730934), (0.017181545495987), (0.172161266207695), (0.047713205218315), (-0.029197663068771), (0.028084233403206), (-0.056424736976624), (-0.162441253662109), (-0.098007299005985), (-0.131831407546997), (-0.138833791017532), (-0.173642992973328), (-0.068805724382401), conv1.bias\n",
      "layer shape =  torch.Size([20])\n",
      "conv2.weight\n",
      "layer shape =  torch.Size([40, 20, 5, 5])\n",
      "conv2.bias\n",
      "layer shape =  torch.Size([40])\n",
      "FC1.weight\n",
      "layer shape =  torch.Size([64, 640])\n",
      "FC1.bias\n",
      "layer shape =  torch.Size([64])\n",
      "Classifier.weight\n",
      "layer shape =  torch.Size([10, 64])\n",
      "Classifier.bias\n",
      "layer shape =  torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# for layer_name in or_dict.keys():\n",
    "#     print(layer_name)\n",
    "#     print(\"layer shape = \", or_dict[layer_name].shape)\n",
    "#     if 'conv1' in layer_name and 'weight' in layer_name:\n",
    "#         print(layer_name)\n",
    "#         print(\"layer shape = \", or_dict[layer_name].shape)\n",
    "        \n",
    "#         for out_ch in range (or_dict[layer_name].shape[0]):\n",
    "#             for in_ch in range (or_dict[layer_name].shape[1]):\n",
    "#                 #print(\"%dth kernel, %dth channel\" % (out_ch, in_ch), file = f)\n",
    "#                 for h in range (or_dict[layer_name].shape[2]):\n",
    "#                     for w in range (or_dict[layer_name].shape[3]):\n",
    "#                         print(\"(%.15f), \" % (float(or_dict[layer_name][out_ch][in_ch][h][w])),end='')\n",
    "#                     #print (\"\\n\", file = f)\n",
    "#                 #print(\"----------------\\n\", file = f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ff012d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "layer shape =  torch.Size([20, 1, 5, 5])\n",
      "conv1.bias\n",
      "layer shape =  torch.Size([20])\n",
      "conv2.weight\n",
      "layer shape =  torch.Size([40, 20, 5, 5])\n",
      "conv2.bias\n",
      "layer shape =  torch.Size([40])\n",
      "FC1.weight\n",
      "layer shape =  torch.Size([64, 640])\n",
      "FC1.bias\n",
      "layer shape =  torch.Size([64])\n",
      "Classifier.weight\n",
      "layer shape =  torch.Size([10, 64])\n",
      "Classifier.bias\n",
      "layer shape =  torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "f = open(\"./para/para.h\", 'w')\n",
    "conv_index = 1\n",
    "fc_index = 1\n",
    "print(\"#include \\\"../../inference/nn.h\\\"\\n\\n\",file = f)\n",
    "for layer_name in or_dict.keys():\n",
    "    if 'conv' in layer_name and 'weight' in layer_name:\n",
    "        print(layer_name)\n",
    "        print(\"layer shape = \", or_dict[layer_name].shape)\n",
    "        print(\"const double conv%d_w_raw[] = {\" %conv_index, file = f)\n",
    "        for out_ch in range (or_dict[layer_name].shape[0]):\n",
    "            for in_ch in range (or_dict[layer_name].shape[1]):\n",
    "                #print(\"%dth kernel, %dth channel\" % (out_ch, in_ch), file = f)\n",
    "                for h in range (or_dict[layer_name].shape[2]):\n",
    "                    for w in range (or_dict[layer_name].shape[3]):\n",
    "                        print(\"(%.15f), \" % (float(or_dict[layer_name][out_ch][in_ch][h][w])),end='',file = f)\n",
    "                    #print (\"\\n\", file = f)\n",
    "                #print(\"----------------\\n\", file = f)\n",
    "        print(\"};\\n\\n\", file = f)\n",
    "    elif 'conv' in layer_name and 'bias' in layer_name:\n",
    "        print(layer_name)\n",
    "        print(\"layer shape = \", or_dict[layer_name].shape)\n",
    "        print(\"const double conv%d_b_raw[] = {\" %conv_index, file = f)\n",
    "        conv_index = conv_index + 1\n",
    "        for ch in range (or_dict[layer_name].shape[0]):\n",
    "            print(\"(%.15f), \" % (float(or_dict[layer_name][ch])),end='',file = f) \n",
    "        print(\"};\\n\\n\", file = f)\n",
    "    elif 'weight' in layer_name:\n",
    "        print(layer_name)\n",
    "        print(\"layer shape = \", or_dict[layer_name].shape)\n",
    "        print(\"const double fc%d_w_raw[] = {\" %fc_index, file = f)\n",
    "        for out_ch in range (or_dict[layer_name].shape[0]):\n",
    "            for in_ch in range (or_dict[layer_name].shape[1]):\n",
    "                 print(\"(%.15f), \" % (float(or_dict[layer_name][out_ch][in_ch])),end='',file = f)\n",
    "        print(\"};\\n\\n\", file = f)\n",
    "    elif 'bias' in layer_name:\n",
    "        print(layer_name)\n",
    "        print(\"layer shape = \", or_dict[layer_name].shape)\n",
    "        print(\"const double fc%d_b_raw[] = {\" %fc_index, file = f)\n",
    "        fc_index = fc_index + 1\n",
    "        for out_ch in range (or_dict[layer_name].shape[0]):\n",
    "            print(\"(%.15f), \" % (float(or_dict[layer_name][out_ch])),end='',file = f)\n",
    "        print(\"};\\n\\n\", file = f)\n",
    "        \n",
    "f.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b96b6cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_v2",
   "language": "python",
   "name": "pytorch_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
